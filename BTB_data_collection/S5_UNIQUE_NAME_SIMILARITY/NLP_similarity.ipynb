{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Needed libraries:\n",
    "#Regex for text cleaning\n",
    "import re\n",
    "\n",
    "#NLP library\n",
    "import nltk\n",
    "\n",
    "#Helper for creating regex \n",
    "import string\n",
    "\n",
    "# Lemmatisation is the algorithmic process of determining the lemma of a word based on its intended meaning.\n",
    "# Lemmatisation depends on correctly identifying the intended part of speech and meaning\n",
    "#of a word in a sentence, as well as within the larger context surrounding that sentence\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl=WordNetLemmatizer()\n",
    "\n",
    "#pattern.en module contains a fast part-of-speech tagger for English (CLiPS)\n",
    "from pattern.en import tag\n",
    "\n",
    "#WordNet is a lexical database for the English language.[1] It groups English words into sets of synonyms called synsets,#\n",
    "#provides short definitions and usage examples, and records a number of relations among these synonym sets or their members. \n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To delete stop words from the text\n",
    "from nltk.corpus import stopwords\n",
    "stopword_list=stopwords.words(\"english\")\n",
    "\n",
    "stopword_list.extend(['www','mail','edu','athttps'])\n",
    "\n",
    "#For tokenizing\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "#remove special characters\n",
    "remove_characters=re.compile('[^a-zA-Z ]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    text = text.decode('utf-8')\n",
    "    text=text.strip()\n",
    "    filtered_sentence=re.sub(remove_characters, r' ', text)\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "#pos_tagged_text is lower case and has WordNet tags, ready to lemmatize    \n",
    "    pos_tagged_text = pos_tag_text(text)\n",
    "    lemmatized_tokens = [wnl.lemmatize(word, pos_tag) if pos_tag\n",
    "                         else word #if word has a tag lemmatize it and add to the list, otherwise just add the word                    \n",
    "                         for word, pos_tag in pos_tagged_text]\n",
    "    lemmatized_text = ' '.join(lemmatized_tokens)\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Annotate text tokens with POS tags\n",
    "def pos_tag_text(text):\n",
    "#Converts Penn Treebank POS tags to WordNet tags    \n",
    "    def penn_to_wn_tags(pos_tag):\n",
    "        if pos_tag.startswith('J'):\n",
    "            return wn.ADJ\n",
    "        elif pos_tag.startswith('V'):\n",
    "            return wn.VERB\n",
    "        elif pos_tag.startswith('N'):\n",
    "            return wn.NOUN\n",
    "        elif pos_tag.startswith('R'):\n",
    "            return wn.ADV\n",
    "        else:\n",
    "            return None\n",
    "    #Use pattern library tagging functions (Penn Treebank syntax)\n",
    "    tagged_text = tag(text)# Result: list of tuples for each sentence\n",
    "    #In order to use lemmatizer we need to change POS tags to WordNet tags and make all words lowercase\n",
    "    tagged_lower_text = [(word.lower(), penn_to_wn_tags(pos_tag))\n",
    "                         for word, pos_tag in\n",
    "                         tagged_text]\n",
    "    return tagged_lower_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function removes stopwords\n",
    "def remove_stopwords(text):\n",
    "    tokens=tokenize_text(text)\n",
    "    filtered_tokens=[token for token in tokens if token not in stopword_list]\n",
    "    filtered_text=\" \".join(filtered_tokens)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This fucntion tokenize words in a sentence\n",
    "def tokenize_text(text):\n",
    "    text = text.decode('utf-8')\n",
    "    tokens=nltk.word_tokenize(text)\n",
    "    tokens=[token.strip() for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_abstract(abstracts):\n",
    "    normalized_abstracts=[]\n",
    "    for abstract in abstracts:\n",
    "        normalized_abstract=[]\n",
    "        #First clean data from any special characters\n",
    "        text=remove_special_characters(abstract)\n",
    "        #Split abstract into sentences\n",
    "        sentences=sent_tokenize(text)\n",
    "        for text in sentences:\n",
    "            text=lemmatize_text(text)\n",
    "            text=remove_stopwords(text)\n",
    "            normalized_abstract.append(text)\n",
    "        normalized_abstract_string=\" \".join(normalized_abstract)\n",
    "        normalized_abstracts.append(normalized_abstract_string)\n",
    "    return normalized_abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GETTING THE FEACURES AND VECTORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_feature_matrix(abstracts, feature_type='frequency',\n",
    "                         ngram_range=(1, 1), min_df=0.00, max_df=1.0):\n",
    "\n",
    "    feature_type = feature_type.lower().strip()  \n",
    "    \n",
    "    if feature_type == 'frequency':\n",
    "        vectorizer = CountVectorizer(binary=False, min_df=min_df,\n",
    "                                     max_df=max_df, ngram_range=ngram_range)\n",
    "    elif feature_type == 'tfidf':\n",
    "        vectorizer = TfidfVectorizer(min_df=min_df, max_df=max_df, \n",
    "                                     ngram_range=ngram_range,use_idf=True)\n",
    "    else:\n",
    "        raise Exception(\"Wrong feature type entered. Possible values:'frequency', 'tfidf'\")\n",
    "\n",
    "    feature_matrix = vectorizer.fit_transform(abstracts).astype(float)\n",
    "\n",
    "    \n",
    "    return vectorizer, feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read im the data, delete additional columns\n",
    "\n",
    "all_articles_tools = pd.read_table('ALL_DATA/NAR/TOOLS/nar_active_links_00_17.txt', keep_default_na=False)\n",
    "all_articles_tools.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "all_articles_tools.drop('Unnamed: 0.1', axis=1, inplace=True)\n",
    "all_articles_tools.drop('Unnamed: 0.1.1', axis=1, inplace=True)\n",
    "#all_articles_tools.drop('Unnamed: 0.1.1.1', axis=1, inplace=True)\n",
    "# create a column for storing related articles\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#this column is going to be used to store names of tools without any integers inside\n",
    "# this is helpful to find different versions of the same tools\n",
    "all_articles_tools[\"main_name\"]=\"NULL\"\n",
    "\n",
    "first_word=re.compile('[^\\s]+')\n",
    "for i in range(len(all_articles_tools)):\n",
    "    tool_name=all_articles_tools[\"name_tool\"][i]\n",
    "    tool_name=re.match(first_word, tool_name).group(0)\n",
    "    tool_name = ''.join([j for j in tool_name if not j.isdigit()])\n",
    "    all_articles_tools[\"main_name\"][i]=tool_name\n",
    "    i=i+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_articles_tools[\"related_articles\"]=\"NULL\"\n",
    "\n",
    "#Give each data point an unique id\n",
    "id_list=range(len(all_articles_tools)+1)[1:]\n",
    "all_articles_tools[\"id\"] = id_list\n",
    "\n",
    "names_of_tools=all_articles_tools.main_name.tolist()\n",
    "# create a list of names of tools that are duplicates\n",
    "import collections\n",
    "duplicated_tools=[item for item, count in collections.Counter(names_of_tools).items() if count > 1]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#list of id of articles which are not \"main articles associated with a tool\"- to be dropped before calculating cosine similarity\n",
    "articles_to_drop_by_ids=[]\n",
    "\n",
    "for name in duplicated_tools:\n",
    "    #ascending = False most recent on the top of the df\n",
    "    related_articles=all_articles_tools.loc[all_articles_tools['main_name'] == name].sort_values(by='date', ascending=False)\n",
    "    ids=[]\n",
    "    ids=related_articles.id.tolist()\n",
    "    index=ids[0]-1\n",
    "    all_articles_tools[\"related_articles\"][index]=ids[1:]\n",
    "    articles_to_drop_by_ids.append(ids[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "year_pattern=re.compile('^20[0-9]{2}')\n",
    "\n",
    "all_articles_tools[\"year\"]=\"NULL\"\n",
    "for i in range(len(all_articles_tools)):\n",
    "    try:\n",
    "        year_matched=re.match( year_pattern, all_articles_tools[\"date\"][i] ).group(0)\n",
    "        all_articles_tools[\"year\"][i] = year_matched\n",
    "\n",
    "    except:\n",
    "        all_articles_tools[\"year\"][i]=\"NULL\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MAKE SURE VIEWS, CITATIONS AND ALTMETRIC SCORE ARE NP INTS\n",
    "all_articles_tools.altmetric_score = all_articles_tools.altmetric_score.astype(np.int64)\n",
    "all_articles_tools.views = all_articles_tools.views.astype(np.int64)\n",
    "all_articles_tools.citations_amount = all_articles_tools.citations_amount.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "all_articles_tools[\"citations_per_year\"]=0.0\n",
    "#Set relative amount of citations- citations per year\n",
    "for i in range(len(all_articles_tools)):\n",
    "    if all_articles_tools[\"citations_amount\"][i] is None:\n",
    "        pass\n",
    "    else:\n",
    "        years=2017 - int(all_articles_tools[\"year\"][i]) +1\n",
    "        yearly_citations=float(all_articles_tools[\"citations_amount\"][i])/float(years) \n",
    "        all_articles_tools[\"citations_per_year\"][i]=int(round(yearly_citations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "all_articles_tools[\"views_per_year\"]=0\n",
    "for i in range(len(all_articles_tools)):\n",
    "    years=2017 - int(all_articles_tools[\"year\"][i])+1\n",
    "    yearly_views= float(all_articles_tools[\"views\"][i]/years)\n",
    "    all_articles_tools[\"views_per_year\"][i]=yearly_views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "#SET RELATIVE AMOUNT OF VIEWS AND SCALE (relative views are in range 4 to 34 so they can be use as sizes of balls\n",
    "# on scatter plots)\n",
    "all_articles_tools[\"relative_views\"]=0\n",
    "max_views=all_articles_tools[\"views_per_year\"].max()\n",
    "\n",
    "\n",
    "length=len(all_articles_tools)       \n",
    "for i in range(length):\n",
    "    yearly_views=float(all_articles_tools[\"views_per_year\"][i])\n",
    "    relative_views=(yearly_views/float(max_views))*30+4\n",
    "    all_articles_tools[\"relative_views\"][i]=int(round(relative_views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#change a list of lists into a regular list\n",
    "articles_to_drop_by_ids = [item for sublist in articles_to_drop_by_ids for item in sublist]\n",
    "\n",
    "# list of ids of main articles\n",
    "\n",
    "id_main_articles=range(len(all_articles_tools)+1)[1:]\n",
    "for item in articles_to_drop_by_ids:\n",
    "    id_main_articles.remove(item)\n",
    "    \n",
    "# I need to create a df only with TOOLS\n",
    "only_tools=DataFrame()\n",
    "only_tools=all_articles_tools[[\"homepage\", \"id\", \"related_articles\", \"name_tool\", \"abstract\", \"citations_per_year\",\"relative_views\", \"topics\" ]]\n",
    "\n",
    "# drop the values which are not main articles\n",
    "for item in articles_to_drop_by_ids:\n",
    "    only_tools = only_tools[only_tools.id != item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "only_tools = only_tools.rename(index=str, columns={\"id\": \"id_article\", \"related_articles\": \"ids_related_articles\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Give each data point an unique id\n",
    "id_list=range(len(only_tools)+1)[1:]\n",
    "only_tools[\"id\"] = id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_abstracts=only_tools.abstract.tolist()\n",
    "names_of_tools=only_tools.name_tool.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# At this point I need to work more on my abstracts and names_of tools to get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add normalized names of tools to stop words\n",
    "# Delete email addresses from the abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_copy=only_tools.name_tool.tolist()\n",
    "all_normalized_names=normalize_abstract(names_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopword_list.extend(['www','mail','edu','athttps'])\n",
    "stopword_list.extend(all_normalized_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2164"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##REGEX FOR GETTING RID OF EMIALS AND WEBSITES\n",
    "website_pattern=re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
    "email_pattern=re.compile(r'http[^\\s]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "for i in range(len(all_abstracts)):\n",
    "    result=re.sub(website_pattern,\"\",  all_abstracts[i])\n",
    "    all_abstracts[i]=re.sub(email_pattern,\"\",  result)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1: NORMALIZE YOUR DATA\n",
    "all_normalized_abstracts=normalize_abstract(all_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 2: EXTRACT FEATURES\n",
    "tfidf_vectorizer, tfidf_matrix=build_feature_matrix(all_normalized_abstracts, feature_type=\"tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names=tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adj_matrix=cosine_similarity(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract the most important features ~ keywords that define the tool, abstract\n",
    "# In order to identify words which were given most weight by tf-idf we need to extract wieights from tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sparse matrix to dense matrix\n",
    "matrix_dense=tfidf_matrix.todense() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_dense #This is a very sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add columns to store info about most importat features=words, and their assosiated weights \n",
    "only_tools[\"feature_list\"]=\"NULL\"\n",
    "only_tools[\"feature_scores\"]=\"NULL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I chose weight of word to be more than 0.10 for word to be considered meaningful\n",
    "#Here we accually collect only index of that word in the list of all the features\n",
    "#In the next step we will change index to word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for i in range(len(only_tools)):\n",
    "    matrix_dense_row=matrix_dense[i]\n",
    "    A = np.squeeze(np.asarray(matrix_dense_row))\n",
    "    important_features=[(d, x) for d, x in enumerate(A) if x > 0.10]\n",
    "    feature_tuples=zip(*important_features)\n",
    "    feature_lists=map(list,feature_tuples )\n",
    "    only_tools[\"feature_list\"][i]=feature_lists[0]\n",
    "    only_tools[\"feature_scores\"][i]=feature_lists[1]\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This column will store actual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "only_tools[\"feature_names\"]=\"NULL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# feature indexes to words\n",
    "for i in range(len(only_tools)):\n",
    "    tool_features=[]\n",
    "    for item in only_tools[\"feature_list\"][i]:\n",
    "        tool_features.append(feature_names[item])\n",
    "    only_tools[\"feature_names\"][i]=tool_features\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add all the list of feature words into one big list check frequency of accurence of the words\n",
    "# choose only globally relevant words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "big_list_of_words=[]\n",
    "for i in range(len(only_tools)):\n",
    "    big_list_of_words.append(only_tools[\"feature_names\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of lists into a list\n",
    "features_list = [item for sublist in big_list_of_words for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add to feature list keywords from the journal itself\n",
    "#check if the journal provides keywords\n",
    "#change the string into list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "counter=collections.Counter(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "only_tools[\"topics_list\"]=\"NULL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "big_list_of_topics=[]\n",
    "for i in range(len(only_tools)):\n",
    "    topics=\"\"\n",
    "    topics= only_tools[\"topics\"][i]\n",
    "    topics1=topics.split(\",\")\n",
    "    only_tools[\"topics_list\"][i]=topics1\n",
    "    big_list_of_topics.append(only_tools[\"topics_list\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# currently big_list_of_topics is a list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of lists into a list\n",
    "topics_list = [item for sublist in big_list_of_topics for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13712"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45932"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We also want to add list of topics which were provided in same of the journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_topics_list=features_list + topics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59644"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_topics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leading_space=re.compile(\"^\\s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Some of the features have leading space-we want to get rid of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(features_topics_list)):\n",
    "    word=re.sub(leading_space, \"\",features_topics_list[i])\n",
    "    features_topics_list[i]=word\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "counter=collections.Counter(features_topics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To get all words=features with weight at least 0.10 is not enough, we want to only consider words that were popular and meaningful\n",
    "#We can manulally decided how many distinct keywords we want to include and remove words which have high weight\n",
    "#but are not meaningful for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'genome', 876),\n",
       " ('genes', 694),\n",
       " (u'rna', 499),\n",
       " (u'protein', 403),\n",
       " (u'datasets', 371),\n",
       " (u'dna', 298),\n",
       " ('', 293),\n",
       " (u'data', 259),\n",
       " (u'sequence', 255),\n",
       " (u'structure', 235),\n",
       " (u'database', 227),\n",
       " (u'software', 207),\n",
       " (u'community', 189),\n",
       " (u'internet', 179),\n",
       " (u'molecule', 168),\n",
       " (u'server', 167),\n",
       " (u'bioinformatics', 164),\n",
       " ('protein structure', 152),\n",
       " (u'mutation', 142),\n",
       " (u'human', 139),\n",
       " ('mice', 129),\n",
       " (u'interaction', 128),\n",
       " (u'secondary', 127),\n",
       " (u'complex', 127),\n",
       " ('gene expression', 125),\n",
       " (u'phenotype', 122),\n",
       " (u'genetic', 121),\n",
       " (u'transcription', 119),\n",
       " (u'genetics', 116),\n",
       " ('binding sites', 116),\n",
       " (u'prediction', 115),\n",
       " (u'structural', 114),\n",
       " (u'site', 114),\n",
       " (u'analysis', 114),\n",
       " (u'annotation', 111),\n",
       " (u'network', 109),\n",
       " (u'genomics', 107),\n",
       " (u'model', 105),\n",
       " (u'expression', 103),\n",
       " (u'alignment', 101),\n",
       " (u'mining', 99),\n",
       " (u'information', 98),\n",
       " (u'tool', 97),\n",
       " (u'method', 93),\n",
       " (u'nucleotides', 88),\n",
       " ('ligands', 87),\n",
       " (u'bind', 87),\n",
       " ('plants', 86),\n",
       " (u'web', 85),\n",
       " (u'new', 84),\n",
       " ('trees (plant)', 83),\n",
       " ('micro rna', 83),\n",
       " (u'motif', 83),\n",
       " (u'set', 81),\n",
       " (u'domain', 81),\n",
       " ('transcription factor', 81),\n",
       " (u'search', 80),\n",
       " (u'regulatory', 79),\n",
       " (u'resource', 78),\n",
       " (u'proteome', 77),\n",
       " ('basic local alignment search tool', 76),\n",
       " (u'functional', 76),\n",
       " (u'genomic', 75),\n",
       " ('libraries', 75),\n",
       " ('cancer', 73),\n",
       " ('peptides', 72),\n",
       " ('single nucleotide polymorphism', 71),\n",
       " (u'query', 70),\n",
       " (u'disease', 70),\n",
       " (u'program', 70),\n",
       " (u'plant', 69),\n",
       " (u'messenger', 69),\n",
       " (u'pdb', 68),\n",
       " (u'region', 68),\n",
       " ('amino acids', 68),\n",
       " (u'user', 67),\n",
       " (u'bacterial', 67),\n",
       " (u'cell', 66),\n",
       " ('protein data bank', 66),\n",
       " (u'arabidopsis', 65),\n",
       " (u'molecular', 65),\n",
       " (u'family', 65),\n",
       " ('amino acid sequence', 65),\n",
       " ('sequence alignment', 65),\n",
       " (u'service', 63),\n",
       " (u'biological', 62),\n",
       " ('databases', 62),\n",
       " (u'specie', 61),\n",
       " (u'benchmarking', 61),\n",
       " (u'drug', 61),\n",
       " ('enzymes', 61),\n",
       " ('maps', 60),\n",
       " (u'atom', 59),\n",
       " (u'technology', 59),\n",
       " (u'function', 59),\n",
       " (u'different', 59),\n",
       " (u'seq', 58),\n",
       " (u'organism', 58),\n",
       " (u'design', 58),\n",
       " (u'residue', 57),\n",
       " (u'proteomics', 57),\n",
       " (u'use', 57),\n",
       " (u'interface', 56),\n",
       " (u'cluster', 56),\n",
       " ('user-computer interface', 56),\n",
       " ('massively-parallel genome sequencing', 55),\n",
       " (u'pathway', 55),\n",
       " (u'peptide', 55),\n",
       " (u'update', 55),\n",
       " (u'system', 54),\n",
       " (u'mirna', 54),\n",
       " (u'genotype', 54),\n",
       " (u'chromatin', 53),\n",
       " (u'binding', 53),\n",
       " ('yeasts', 53),\n",
       " (u'profile', 53),\n",
       " (u'coding', 53),\n",
       " ('graphical displays', 52),\n",
       " ('chromosomes', 52),\n",
       " (u'transcript', 51),\n",
       " (u'element', 50),\n",
       " (u'workflow', 50),\n",
       " (u'bacteria', 50),\n",
       " (u'small', 48),\n",
       " (u'predict', 48),\n",
       " (u'base', 47),\n",
       " (u'similarity', 47),\n",
       " (u'chemical', 47),\n",
       " (u'pattern', 47),\n",
       " (u'methylation', 47),\n",
       " (u'feature', 46),\n",
       " (u'factor', 46),\n",
       " (u'consensus', 46),\n",
       " (u'algorithm', 46),\n",
       " (u'multiple', 46),\n",
       " (u'rice', 45),\n",
       " (u'polymorphism', 45),\n",
       " ('binding (molecular function)', 45),\n",
       " (u'version', 45),\n",
       " (u'inference', 44),\n",
       " (u'type', 44),\n",
       " (u'sample', 44),\n",
       " (u'heterogeneity', 44),\n",
       " (u'metadata', 43),\n",
       " ('exons', 43),\n",
       " (u'collection', 43),\n",
       " (u'score', 42),\n",
       " (u'study', 42),\n",
       " ('candidate disease gene', 42),\n",
       " (u'map', 42),\n",
       " (u'entry', 42),\n",
       " (u'acid', 42),\n",
       " (u'phylogenetic', 41),\n",
       " (u'research', 41),\n",
       " (u'evolutionary', 41),\n",
       " (u'identify', 41),\n",
       " (u'affinity', 41),\n",
       " (u'provide', 40),\n",
       " ('nucleic acids', 39),\n",
       " ('mammals', 39),\n",
       " (u'quality', 39),\n",
       " (u'annotate', 39),\n",
       " (u'module', 39),\n",
       " ('sequence analysis', 38),\n",
       " (u'mirnas', 38),\n",
       " (u'support', 38),\n",
       " (u'enzyme', 38),\n",
       " (u'application', 38),\n",
       " (u'contain', 38),\n",
       " (u'compound', 38),\n",
       " (u'splice', 37),\n",
       " (u'transcriptional', 37),\n",
       " (u'co', 37),\n",
       " (u'curated', 37),\n",
       " (u'experiment', 37),\n",
       " (u'reference', 37),\n",
       " (u'association', 37),\n",
       " (u'generate', 37),\n",
       " (u'identification', 37),\n",
       " (u'classification', 36),\n",
       " (u'tree', 36),\n",
       " (u'number', 36),\n",
       " (u'comparative', 36),\n",
       " (u'non', 36),\n",
       " (u'amino', 36),\n",
       " (u'signal', 36),\n",
       " (u'variation', 36),\n",
       " ('filters', 36),\n",
       " (u'promoter', 36),\n",
       " (u'precision', 36),\n",
       " (u'conserve', 35),\n",
       " (u'ontology', 35),\n",
       " (u'sequencing', 35),\n",
       " (u'group', 35),\n",
       " (u'several', 35),\n",
       " ('host (organism)', 35),\n",
       " (u'link', 34),\n",
       " (u'id', 34),\n",
       " (u'tissue', 34),\n",
       " (u'candidate', 34),\n",
       " (u'associate', 34),\n",
       " ('metabolites', 34),\n",
       " (u'include', 34),\n",
       " ('united states national institutes of health', 33),\n",
       " (u'project', 33),\n",
       " (u'release', 33),\n",
       " (u'oligonucleotides', 33),\n",
       " (u'templates', 33),\n",
       " (u'complete', 33),\n",
       " (u'change', 33),\n",
       " (u'library', 33),\n",
       " (u'display', 33),\n",
       " (u'mrna', 33),\n",
       " (u'energy', 33),\n",
       " (u'complementary', 33),\n",
       " (u'level', 33),\n",
       " (u'list', 33),\n",
       " (u'virus', 32),\n",
       " (u'high', 32),\n",
       " (u'visualization', 32),\n",
       " ('knowledge bases', 32),\n",
       " (u'go', 32),\n",
       " (u'may', 32),\n",
       " (u'file', 32),\n",
       " (u'access', 32),\n",
       " (u'approach', 32),\n",
       " (u'term', 32),\n",
       " (u'laboratory', 31),\n",
       " (u'macromolecule', 31),\n",
       " (u'coordinate', 31),\n",
       " (u'mouse', 31),\n",
       " (u'template', 31),\n",
       " (u'homology', 31),\n",
       " ('eukaryotic cell', 31),\n",
       " (u'nucleotide', 31),\n",
       " (u'know', 31),\n",
       " (u'result', 30),\n",
       " (u'exon', 30),\n",
       " (u'million', 30),\n",
       " (u'tf', 30),\n",
       " (u'input', 30),\n",
       " (u'accuracy', 30),\n",
       " (u'fragment', 30),\n",
       " (u'property', 30),\n",
       " ('base sequence', 30),\n",
       " (u'modification', 30),\n",
       " ('pathogenic organism', 30),\n",
       " (u'metabolic', 30),\n",
       " (u'knowledge', 30),\n",
       " (u'metabolism', 30),\n",
       " (u'various', 30),\n",
       " (u'xml', 29),\n",
       " (u'process', 29),\n",
       " (u'microbial', 29),\n",
       " (u'biology', 29),\n",
       " (u'ribosomal', 29),\n",
       " (u'value', 29),\n",
       " (u'effect', 29),\n",
       " (u'well', 29),\n",
       " (u'dynamic', 29),\n",
       " (u'mutagenesis', 29),\n",
       " (u'integrate', 29),\n",
       " (u'potential', 29),\n",
       " (u'two', 29),\n",
       " (u'find', 29),\n",
       " ('viruses', 29),\n",
       " ('rna splicing', 29),\n",
       " (u'clinical', 29),\n",
       " (u'literature', 29),\n",
       " (u'pipeline', 29),\n",
       " (u'local', 29),\n",
       " ('oncogenes', 28),\n",
       " (u'alleles', 28),\n",
       " (u'anatomy', 28),\n",
       " (u'ribosomes', 28),\n",
       " (u'test', 28),\n",
       " (u'archaea', 28),\n",
       " (u'novel', 28),\n",
       " ('polymerase chain reaction', 28),\n",
       " ('expressed sequence tags', 28),\n",
       " (u'across', 28),\n",
       " (u'drosophila', 28),\n",
       " (u'engineering', 28),\n",
       " ('gene expression regulation', 28),\n",
       " (u'related', 28),\n",
       " (u'detect', 27),\n",
       " (u'single', 27),\n",
       " (u'phylogeny', 27),\n",
       " (u'computational', 27),\n",
       " (u'zebrafish', 27),\n",
       " (u'tfs', 27),\n",
       " (u'give', 27),\n",
       " (u'probe', 27),\n",
       " (u'regulation', 27),\n",
       " (u'enrichment', 27),\n",
       " (u'text', 27),\n",
       " (u'position', 27),\n",
       " (u'host', 27),\n",
       " (u'report', 27),\n",
       " (u'specific', 27),\n",
       " (u'short', 27),\n",
       " ('introns', 26),\n",
       " (u'eukaryotic', 26),\n",
       " (u'enable', 26),\n",
       " (u'vocabulary', 26),\n",
       " (u'large', 26),\n",
       " (u'compute', 26),\n",
       " (u'chip', 26),\n",
       " (u'describe', 26),\n",
       " (u'similar', 26),\n",
       " (u'experimental', 26),\n",
       " (u'receptor', 26),\n",
       " (u'website', 26),\n",
       " (u'alternative', 26),\n",
       " (u'scale', 26),\n",
       " (u'biotechnology', 26),\n",
       " (u'researcher', 26),\n",
       " (u'reaction', 26),\n",
       " (u'regional', 25)]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(319)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_keywords_tuples=counter.most_common(319)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_keywords = zip(*my_keywords_tuples)\n",
    "my_keywords =my_keywords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is an example of featured keywords for one of the abstracts before cleaning it.\n",
    "#Here we see all the words with weight more than 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'activate',\n",
       " u'activation',\n",
       " u'apparent',\n",
       " u'bacillus',\n",
       " u'bind',\n",
       " u'box',\n",
       " u'competence',\n",
       " u'consensus',\n",
       " u'factor',\n",
       " u'macroarrays',\n",
       " u'ofbacillus',\n",
       " u'presence',\n",
       " u'promoter',\n",
       " u'putative',\n",
       " u'regulation',\n",
       " u'site',\n",
       " u'subtilis',\n",
       " u'subtiliscontains',\n",
       " u'supposition',\n",
       " u'take',\n",
       " u'transcription',\n",
       " u'unreliable',\n",
       " u'valid']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_tools[\"feature_names\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here are keywords associated to that abstract by journal maintainer \n",
    "#(ONLY 2 out of 4 journal provide keywords, topic )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bacillus subtilis',\n",
       " 'binding sites',\n",
       " 'consensus sequence',\n",
       " 'dna',\n",
       " 'genes',\n",
       " 'genome',\n",
       " 'operon',\n",
       " 'promoter regions (genetics)',\n",
       " 'transcription factor',\n",
       " 'competence',\n",
       " 'rna']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_tools[\"topics_list\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "only_tools[\"keywords_dirty\"]=\"NULL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(only_tools)):\n",
    "    only_tools[\"keywords_dirty\"][i]= only_tools[\"feature_names\"][i] + only_tools[\"topics_list\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_keywords_list=list(my_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decided to delete some items manually....I actually removed many more words not shown here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_keywords_list.remove(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_keywords_list.remove(\"co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_keywords_list.remove(\"non\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_keywords_list.remove(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_keywords_list.remove(\"go\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_keywords_list.remove(\"may\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_keywords_list.remove(\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_keywords_list.remove(\"xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_keywords_list.remove(\"two\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_keywords_list.remove(\"tfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#HERE IS MY FINAL LIST OF RELEVANT KEYWORDS, ONLY THESE WORDS CAN BE FEATURE AS A TOOL'S\n",
    "#KEYWORDS ON THE TOOL'S LANDING PAGE, THIS WORDS ALSO COULD HELP WITH SEARCH RESULTS\n",
    "#ABSTRACTS WITH WORD="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#my_keywords_list \n",
    "#this list should be improved many more words to delete\n",
    "# we should create a black list of words that score high but should not be in the final keywords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "only_tools[\"tool_keywords\"]=\"NULL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#Saving only relevant keywords\n",
    "for i in range(len(only_tools)):\n",
    "    all_features=only_tools[\"keywords_dirty\"][i]\n",
    "    only_relevant = [word for word in all_features if word  in my_keywords_list]\n",
    "    only_tools[\"tool_keywords\"][i]=only_relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CheCk how the keywords for each abstract look like\n",
    "#only_tools[\"tool_keywords\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# delete words that are not your keywords from only_tools[\"feature_names\"][i]=\n",
    "#[rowData for index, rowData in journal_data.iterrows() if rowData['tag'] not in tag_blacklist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This would add 9 closets neighbors index and similarity level for recommandaction system purposes\n",
    "only_tools[\"closets_neighbor_1\"]=\"NULL\"\n",
    "only_tools[\"closets_neighbor_2\"]=\"NULL\"\n",
    "only_tools[\"closets_neighbor_3\"]=\"NULL\"\n",
    "only_tools[\"closets_neighbor_4\"]=\"NULL\"\n",
    "only_tools[\"closets_neighbor_5\"]=\"NULL\"\n",
    "only_tools[\"closets_neighbor_6\"]=\"NULL\"\n",
    "only_tools[\"closets_neighbor_7\"]=\"NULL\"\n",
    "only_tools[\"closets_neighbor_8\"]=\"NULL\"\n",
    "only_tools[\"closets_neighbor_9\"]=\"NULL\"\n",
    "only_tools[\"similarity_neighbor_1\"]=\"NULL\"\n",
    "only_tools[\"similarity_neighbor_2\"]=\"NULL\"\n",
    "only_tools[\"similarity_neighbor_3\"]=\"NULL\"\n",
    "only_tools[\"similarity_neighbor_4\"]=\"NULL\"\n",
    "only_tools[\"similarity_neighbor_5\"]=\"NULL\"\n",
    "only_tools[\"similarity_neighbor_6\"]=\"NULL\"\n",
    "only_tools[\"similarity_neighbor_7\"]=\"NULL\"\n",
    "only_tools[\"similarity_neighbor_8\"]=\"NULL\"\n",
    "only_tools[\"similarity_neighbor_9\"]=\"NULL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/maayanlab/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "data_length=len(only_tools)\n",
    "for i in range (data_length):\n",
    "    sorted_similarity=sorted(((value, index) for index, value in enumerate(adj_matrix[i])), reverse=True)\n",
    "    closest_list=[]\n",
    "    closest_list=sorted_similarity[1:14]\n",
    "#set up the values of the closest neighboors\n",
    "    only_tools[\"closets_neighbor_1\"][i] = (closest_list[0][1] + 1)# index to id\n",
    "    only_tools[\"similarity_neighbor_1\"][i] = closest_list[0][0]\n",
    "#    \n",
    "    only_tools[\"closets_neighbor_2\"][i] =(closest_list[1][1] + 1)\n",
    "    only_tools[\"similarity_neighbor_2\"][i] = closest_list[1][0]\n",
    "#    \n",
    "    only_tools[\"closets_neighbor_3\"][i] =(closest_list[2][1] + 1)\n",
    "    only_tools[\"similarity_neighbor_3\"][i] = closest_list[2][0]\n",
    "#    \n",
    "    only_tools[\"closets_neighbor_4\"][i] =(closest_list[3][1] + 1)\n",
    "    only_tools[\"similarity_neighbor_4\"][i] = closest_list[3][0]\n",
    "    \n",
    "    only_tools[\"closets_neighbor_5\"][i] = (closest_list[4][1] + 1)# index to id\n",
    "    only_tools[\"similarity_neighbor_5\"][i] = closest_list[4][0]\n",
    "#    \n",
    "    only_tools[\"closets_neighbor_5\"][i] =(closest_list[5][1] + 1)\n",
    "    only_tools[\"similarity_neighbor_5\"][i] = closest_list[5][0]\n",
    "#    \n",
    "    only_tools[\"closets_neighbor_6\"][i] =(closest_list[6][1] + 1)\n",
    "    only_tools[\"similarity_neighbor_6\"][i] = closest_list[6][0]\n",
    "#    \n",
    "    only_tools[\"closets_neighbor_7\"][i] =(closest_list[7][1] + 1)\n",
    "    only_tools[\"similarity_neighbor_7\"][i] = closest_list[7][0]\n",
    "    \n",
    "    only_tools[\"closets_neighbor_8\"][i] =(closest_list[8][1] + 1)\n",
    "    only_tools[\"similarity_neighbor_8\"][i] = closest_list[8][0]\n",
    "    \n",
    "    only_tools[\"closets_neighbor_9\"][i] =(closest_list[9][1] + 1)\n",
    "    only_tools[\"similarity_neighbor_9\"][i] = closest_list[9][0]\n",
    "\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adj_matrix_nor =adj_matrix / adj_matrix.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in order to use t-sne you need to change cosine similarity to cosine distance \n",
    "#cosine distance = 1 - cosine similarity\n",
    "#REST OF THE CODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Before you RUN it take a look at the parameters\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "#MODEL 3D\n",
    "model3D=TSNE(n_components=3, perplexity=15.0, early_exaggeration=4.0, learning_rate=100.0, n_iter=8000, n_iter_without_progress=30, min_grad_norm=1e-07, metric='precomputed', init='random', verbose=0, random_state=None, method='barnes_hut', angle=0.5)\n",
    "np.set_printoptions(suppress=True)\n",
    "TSNE_data3D=model3D.fit_transform(1-adj_matrix_nor) \n",
    "transformed_TSNE_data3D=TSNE_data3D.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MODEL 2D\n",
    "\n",
    "model2D=TSNE(n_components=2, perplexity=10.0, early_exaggeration=4.0, learning_rate=100.0, n_iter=8000, n_iter_without_progress=30, min_grad_norm=1e-07, metric='precomputed', init='random', verbose=0, random_state=None, method='barnes_hut', angle=0.5)\n",
    "np.set_printoptions(suppress=True)\n",
    "TSNE_data2D=model2D.fit_transform(1-adj_matrix_nor) \n",
    "transformed_TSNE_data2D=TSNE_data2D.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Manipulating data frame to add new information\n",
    "\n",
    "#addig additional columns to data frame\n",
    "only_tools[\"x\"]=0\n",
    "only_tools[\"y\"]=0\n",
    "only_tools[\"z\"]=0\n",
    "only_tools[\"closest_neighbors\"]=\"NULL\"\n",
    "only_tools[\"x_2d\"]=0\n",
    "only_tools[\"y_2d\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#assign the right values to the columns  3D case\n",
    "x_coordinate = transformed_TSNE_data3D[0]\n",
    "len(x_coordinate)\n",
    "only_tools[\"x\"]=x_coordinate\n",
    "\n",
    "y_coordinate = transformed_TSNE_data3D[1]\n",
    "only_tools[\"y\"] = y_coordinate\n",
    "\n",
    "z_coordinate = transformed_TSNE_data3D[2]\n",
    "only_tools[\"z\"]=z_coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#assign the right values to the columns  2D case\n",
    "x_coordinate_2d = transformed_TSNE_data2D[0]\n",
    "only_tools[\"x_2d\"]=x_coordinate_2d\n",
    "\n",
    "y_coordinate_2d = transformed_TSNE_data2D[1]\n",
    "only_tools[\"y_2d\"] = y_coordinate_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "only_tools.to_csv(\"BEST2_main_tools.txt\",sep='\\t', encoding='utf-8')\n",
    "all_articles_tools.to_csv(\"BEST2_tools_articles.txt\",sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CODE FOR CANVAS VISUALIZATION\n",
    "similar_tool_canvas=similar_tools[[\"main_tool\", \"similar_tool_fk\", \"similarity\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(similar_tool_canvas)):\n",
    "    tool_id=similar_tool_canvas[\"main_tool\"][i]\n",
    "    similar_tool_canvas[\"main_tool\"][i]= tools[\"name_tool\"][tool_id-1]\n",
    "    similar_tool_id=similar_tool_canvas[\"similar_tool_fk\"][i]\n",
    "    similar_tool_canvas[\"similar_tool_fk\"][i]= tools[\"name_tool\"][similar_tool_id-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similar_tool_canvas.to_csv(\"canvas.txt\",sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similar_tool_canvas.to_csv(\"canvas2.txt\", header=False, index=False,sep='\\t', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
